{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requirements\n",
    "# Comment if already satisfied\n",
    "#!pip install -U jupyter\n",
    "#!pip install datasets transformers accelerate torch torchinfo xlrd seaborn sklearn torchmetrics\n",
    "#!pip install --upgrade --quiet jupyter_client ipywidgets\n",
    "#!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = \"../data/\"\n",
    "LM_DIR = \"./out/language_model\"\n",
    "OUT_DIR = \"./out/classification_model\"\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_training_history(train_history, val_history, model_name, phase_name, out_dir):\n",
    "    fig, (loss_ax, acc_ax) = plt.subplots(figsize=(12, 8), nrows=2)\n",
    "    fig.suptitle(f\"{model_name} - {phase_name} History\")\n",
    "    loss_ax.set_title(\"Cross Entropy Loss\")\n",
    "    loss_ax.plot(train_history[\"loss\"], label=\"train\")\n",
    "    loss_ax.plot(val_history[\"loss\"], label=\"val\")\n",
    "    loss_ax.legend(loc=\"best\")\n",
    "\n",
    "    acc_ax.set_title(\"Classification accuracy\")\n",
    "    acc_ax.plot(train_history[\"accuracy\"], label=\"train\")\n",
    "    acc_ax.plot(val_history[\"accuracy\"], label=\"val\")\n",
    "    loss_ax.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    fig.savefig(f\"{out_dir}/{model_name}_{phase_name}_history.png\", dpi=150, bbox_inches='tight')\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#articles = pd.read_excel(os.path.join(DATA_DIR, \"OpArticles_ADUs.xlsx\"))\n",
    "adus = pd.read_csv(os.path.join(DATA_DIR, \"OpArticles_ADUs.csv\")) # If pandas version doesn't support .xlsx, use this instaed\n",
    "\n",
    "adus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Label Ratios\")\n",
    "print(adus[\"label\"].value_counts() / len(adus[\"label\"]))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.countplot(data=adus, x=\"label\", ax=ax)\n",
    "ax.set_title(\"Distribution of labels on ADUs\")\n",
    "ax.set_xlabel(\"Label\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "fig.savefig(f\"{OUT_DIR}/label_distribution_full.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"Fact\", \"Policy\", \"Value\", \"Value(+)\", \"Value(-)\"]\n",
    "N_CLASSES = len(classes)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "adus[\"label\"] = le.fit_transform(adus[\"label\"])\n",
    "\n",
    "adus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train, Validation and Test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintain the ratios of labels across splits\n",
    "train_val_adus = adus.groupby(\"label\").sample(frac=0.8, random_state=SEED)\n",
    "test_adus = adus.loc[adus.index.difference(train_val_adus.index)]\n",
    "\n",
    "train_adus = train_val_adus.groupby(\"label\").sample(frac=0.8, random_state=SEED)\n",
    "val_adus = train_val_adus.loc[train_val_adus.index.difference(train_adus.index)]\n",
    "\n",
    "fig, (train_ax, val_ax, test_ax) = plt.subplots(figsize=(16, 4), ncols=3)\n",
    "for split, df, ax in zip([\"Train\", \"Validation\", \"Test\"], [train_adus, val_adus, test_adus], [train_ax, val_ax, test_ax]):\n",
    "    df_labels = le.inverse_transform(df[\"label\"])\n",
    "    sns.countplot(x=df_labels, ax=ax, order=[\"Value\", \"Fact\", \"Value(-)\", \"Value(+)\", \"Policy\"])\n",
    "    ax.set_title(f\"Distribution of labels on {split} ADUs\")\n",
    "    ax.set_xlabel(\"Label\")\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    \n",
    "    print(f\"{split} Label Ratios\")\n",
    "    print(pd.Series(df_labels).value_counts() / len(df_labels))\n",
    "fig.savefig(f\"{OUT_DIR}/label_distribution_splits.png\", dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_adus.reset_index(inplace=True)\n",
    "val_adus.reset_index(inplace=True)\n",
    "test_adus.reset_index(inplace=True)\n",
    "\n",
    "train_adus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Dataset to HF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.dataset_dict import DatasetDict\n",
    "from datasets import Dataset, DatasetInfo, Features, Value, ClassLabel\n",
    "info = DatasetInfo(\n",
    "    features=Features({\n",
    "        \"index\": Value(\"int64\"),\n",
    "        \"tokens\": Value(\"string\"),\n",
    "        \"label\": ClassLabel(num_classes=N_CLASSES, names=le.classes_.tolist()),\n",
    "        \"article_id\": Value(\"string\"),\n",
    "        \"annotator\": Value(\"string\"),\n",
    "        \"node\": Value(\"int64\"),\n",
    "        \"ranges\": Value(\"string\"),\n",
    "    })\n",
    ")\n",
    "\n",
    "adus_dataset = DatasetDict({\n",
    "    \"train\": Dataset.from_pandas(train_adus, preserve_index=True, info=info),\n",
    "    \"val\": Dataset.from_pandas(val_adus, preserve_index=True, info=info),\n",
    "    \"test\": Dataset.from_pandas(test_adus, preserve_index=True, info=info)\n",
    "})\n",
    "\n",
    "print(adus_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adus_dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adus_dataset = adus_dataset.remove_columns([\"annotator\", \"node\", \"ranges\"])\n",
    "print(adus_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Base Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-large-portuguese-cased', do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(batch):\n",
    "    result = tokenizer(batch[\"tokens\"])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_dataset = adus_dataset.map(\n",
    "    tokenize, batched=True, remove_columns=[\"article_id\", \"tokens\"]\n",
    ")\n",
    "\n",
    "print(cls_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "BATCH_SIZE = 64 # Tested with NVIDIA Tesla T4 16GB\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=cls_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=cls_dataset[\"val\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=cls_dataset[\"test\"],\n",
    "    shuffle=False,\n",
    "    batch_size=1,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from torchinfo import summary\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"{LM_DIR}/best\", num_labels=N_CLASSES)\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "optimizer = optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=5e-3,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=1e-4,\n",
    "    amsgrad=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Epoch Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "synonyms = {}\n",
    "\n",
    "with open(DATA_DIR + \"/synonyms.json\", \"r\", encoding=\"utf-8\") as synonyms_json:\n",
    "    synonyms = json.load(synonyms_json)\n",
    "\n",
    "synonyms_tokenized = {}\n",
    "n = 0\n",
    "for k, v in synonyms.items():\n",
    "    tokens_k = tokenizer.encode(k, add_special_tokens=False)\n",
    "\n",
    "    # Don't allow multi token for simplicity\n",
    "    if len(tokens_k) > 1:\n",
    "        continue\n",
    "\n",
    "    token_v = [tokenizer.encode(s, add_special_tokens=False) for s in v]\n",
    "    token_v = [tv[0] for tv in token_v if len(tv) == 1]\n",
    "\n",
    "    if token_v:\n",
    "        synonyms_tokenized[tokens_k[0]] = token_v\n",
    "\n",
    "    \n",
    "def add_synonyms(input_ids, p = 0.05):\n",
    "    for i in range(len(input_ids)):\n",
    "        inputId = input_ids[i].item()\n",
    "        if (inputId in synonyms_tokenized) and np.random.binomial(1, p):\n",
    "            input_ids[i] = np.random.choice(synonyms_tokenized[inputId])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "def epoch_iter(dataloader, model, is_train = True, optimizer=None, lr_scheduler=None):\n",
    "    if is_train:\n",
    "        assert optimizer is not None, \"When training, please provide an optimizer.\"\n",
    "      \n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    if is_train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    probs = []\n",
    "    preds = []\n",
    "    expected_labels = []\n",
    "    aduIds = []\n",
    "    \n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for batch in tqdm(dataloader):\n",
    "            index = batch.pop(\"index\")\n",
    "\n",
    "            if is_train:\n",
    "                for b_input_ids in batch[\"input_ids\"]:\n",
    "                    add_synonyms(b_input_ids, p=0.3)\n",
    "            \n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "\n",
    "            if is_train:\n",
    "                optimizer.zero_grad()\n",
    "                accelerator.backward(scaler.scale(loss))\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "\n",
    "            prob = F.softmax(outputs.logits, dim=1)\n",
    "            final_pred = torch.argmax(prob, dim=1)\n",
    "\n",
    "            aduIds.extend(index.detach().cpu().numpy())\n",
    "            probs.extend(prob.detach().cpu().numpy())\n",
    "            preds.extend(final_pred.detach().cpu().numpy())\n",
    "            expected_labels.extend(batch[\"labels\"].detach().cpu().numpy())\n",
    "            \n",
    "        if is_train and lr_scheduler is not None:\n",
    "            lr_scheduler.step()\n",
    "        \n",
    "    return (expected_labels, preds, probs, aduIds), total_loss / num_batches\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "import torchmetrics\n",
    "\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=optimizer,\n",
    "    gamma=0.9,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "metric_scorer = torchmetrics.Accuracy(\n",
    "    threshold=0.5,\n",
    "    num_classes=N_CLASSES,\n",
    "    average=\"micro\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\": []\n",
    "}\n",
    "\n",
    "val_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\": []\n",
    "}\n",
    "\n",
    "model.bert.requires_grad_(False) # Freeze language model layer\n",
    "\n",
    "best_loss = np.inf\n",
    "best_accuracy = 0\n",
    "best_epoch = -1\n",
    "\n",
    "print(f\"Starting classification language model training...\")\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"Epoch[{epoch}/{NUM_EPOCHS}]\")\n",
    "    \n",
    "    (train_target, train_preds, train_probs, _), train_loss = epoch_iter(\n",
    "        dataloader=train_dataloader,\n",
    "        model=model,\n",
    "        is_train=True,\n",
    "        optimizer=optimizer,\n",
    "        lr_scheduler=lr_scheduler\n",
    "    )\n",
    "    \n",
    "    train_accuracy = metric_scorer(torch.tensor(np.array(train_probs)), torch.tensor(np.array(train_target))).item()\n",
    "    print(f\"Training loss: {train_loss:.3f}\\t Training micro accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "    (val_target, val_preds, val_probs, _), val_loss = epoch_iter(\n",
    "        dataloader=val_dataloader,\n",
    "        model=model,\n",
    "        is_train=False,\n",
    "    )\n",
    "\n",
    "    val_accuracy = metric_scorer(torch.tensor(np.array(val_probs)), torch.tensor(np.array(val_target))).item()\n",
    "    print(f\"Validation loss: {val_loss:.3f}\\t Validation micro accuracy: {val_accuracy:.3f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        best_accuracy = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        \n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(f\"{OUT_DIR}/best\", save_function=accelerator.save)\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(f\"{OUT_DIR}/latest\", save_function=accelerator.save)\n",
    "\n",
    "    train_history[\"loss\"].append(train_loss)\n",
    "    train_history[\"accuracy\"].append(train_accuracy)\n",
    "\n",
    "    val_history[\"loss\"].append(val_loss)\n",
    "    val_history[\"accuracy\"].append(val_accuracy)\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    \n",
    "print(\n",
    "    f\"\\nFinished training...\"\n",
    "    f\"\\nBest epoch: {best_epoch}\\t Validation loss on best epoch: {best_loss}\\t Accuracy on best epoch: {best_accuracy}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_history(train_history=train_history, val_history=val_history, model_name=\"BERT-ADU-CLS\", phase_name=\"FREEZE\", out_dir=OUT_DIR)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear GPU memory for guarantees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model = None\n",
    "train_dataloader = None\n",
    "val_dataloader = None\n",
    "lr_scheduler = None\n",
    "optimizer = None\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.mem_get_info(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load best model from first training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 16 # Tested with NVIDIA Tesla T4 16GB\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=cls_dataset[\"train\"],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator\n",
    ")\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=cls_dataset[\"val\"],\n",
    "    shuffle=False,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f\"{OUT_DIR}/best\", num_labels=N_CLASSES)\n",
    "\n",
    "print(\"Loaded best model...\")\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_optimizer = optim.Adam(\n",
    "    params=model.parameters(),\n",
    "    lr=1e-5,\n",
    "    betas=(0.9, 0.999),\n",
    "    weight_decay=5e-4,\n",
    "    amsgrad=True\n",
    ")\n",
    "\n",
    "accelerator = Accelerator()\n",
    "\n",
    "model, ft_optimizer, train_dataloader, val_dataloader = accelerator.prepare(\n",
    "    model, ft_optimizer, train_dataloader, val_dataloader\n",
    ")\n",
    "\n",
    "ft_lr_scheduler = optim.lr_scheduler.ExponentialLR(\n",
    "    optimizer=ft_optimizer,\n",
    "    gamma=0.9,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_train_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\": []\n",
    "}\n",
    "\n",
    "ft_val_history = {\n",
    "    \"loss\": [],\n",
    "    \"accuracy\": []\n",
    "}\n",
    "\n",
    "FT_NUM_EPOCHS = 15\n",
    "model.bert.requires_grad_(True) # Unfreeze language model layer\n",
    "\n",
    "ft_best_loss = best_loss \n",
    "ft_best_accuracy = best_accuracy\n",
    "ft_best_epoch = -1\n",
    "\n",
    "print(f\"Starting classification language model fine-tuning...\")\n",
    "\n",
    "for epoch in range(1, FT_NUM_EPOCHS + 1):\n",
    "    print(f\"Epoch[{epoch}/{FT_NUM_EPOCHS}]\")\n",
    "    \n",
    "    (train_target, train_preds, train_probs, _), train_loss = epoch_iter(\n",
    "        dataloader=train_dataloader,\n",
    "        model=model,\n",
    "        is_train=True,\n",
    "        optimizer=ft_optimizer,\n",
    "        lr_scheduler=ft_lr_scheduler\n",
    "    )\n",
    "    \n",
    "    train_accuracy = metric_scorer(torch.tensor(np.array(train_probs)), torch.tensor(np.array(train_target))).item()\n",
    "    print(f\"Training loss: {train_loss:.3f}\\t Training micro accuracy: {train_accuracy:.3f}\")\n",
    "\n",
    "    (val_target, val_preds, val_probs, _), val_loss = epoch_iter(\n",
    "        dataloader=val_dataloader,\n",
    "        model=model,\n",
    "        is_train=False,\n",
    "    )\n",
    "\n",
    "    val_accuracy = metric_scorer(torch.tensor(np.array(val_probs)), torch.tensor(np.array(val_target))).item()\n",
    "    print(f\"Validation loss: {val_loss:.3f}\\t Validation micro accuracy: {val_accuracy:.3f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_loss < ft_best_loss:\n",
    "        ft_best_loss = val_loss\n",
    "        ft_best_accuracy = val_accuracy\n",
    "        ft_best_epoch = epoch\n",
    "        \n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model = accelerator.unwrap_model(model)\n",
    "        unwrapped_model.save_pretrained(f\"{OUT_DIR}/fine_tuned/best\", save_function=accelerator.save)\n",
    "\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(f\"{OUT_DIR}/fine_tuned/latest\", save_function=accelerator.save)\n",
    "\n",
    "    ft_train_history[\"loss\"].append(train_loss)\n",
    "    ft_train_history[\"accuracy\"].append(train_accuracy)\n",
    "\n",
    "    ft_val_history[\"loss\"].append(val_loss)\n",
    "    ft_val_history[\"accuracy\"].append(val_accuracy)\n",
    "\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    \n",
    "print(\n",
    "    f\"\\nFinished fine-tuning...\"\n",
    "    f\"\\nBest epoch: {ft_best_epoch}\\t Validation loss on best epoch: {ft_best_loss}\\t Accuracy on best epoch: {ft_best_accuracy}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_training_history(train_history=ft_train_history, val_history=ft_val_history, model_name=\"BERT-ADU-CLS\", phase_name=\"FINE-TUNE\", out_dir=OUT_DIR)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "model = None\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.mem_get_info(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(f\"{OUT_DIR}/fine_tuned/best\", num_labels=N_CLASSES)\n",
    "\n",
    "print(\"Loaded best fine-tuned model...\")\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator()\n",
    "\n",
    "model, test_dataloader = accelerator.prepare(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(test_target, test_preds, test_probs, test_ids), test_loss = epoch_iter(\n",
    "    dataloader=test_dataloader,\n",
    "    model=model,\n",
    "    is_train=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true=test_target, y_pred=test_preds, target_names=le.classes_.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getErrors(adu_dataframe, adu_ids, y_true, y_pred):\n",
    "    df = pd.DataFrame(columns=[\"id\", \"adu\", \"target\", \"predicted\"])\n",
    "    for (aduId, correct, predicted) in zip(adu_ids, y_true, y_pred):\n",
    "        if correct == predicted:\n",
    "            continue\n",
    "        row = {\n",
    "            \"id\": aduId,\n",
    "            \"adu\": adu_dataframe.iloc[aduId][\"tokens\"],\n",
    "            \"target\": correct,\n",
    "            \"predicted\": predicted\n",
    "        }\n",
    "        \n",
    "        df = df.append(row, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "errors_df = getErrors(adus, test_ids, le.inverse_transform(test_target), le.inverse_transform(test_preds))\n",
    "errors_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_df.to_csv(f\"{OUT_DIR}/test_errors.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "706ee1819b983a943bbea807e6681581497887a5e921ebf85b777ef931d5d8ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
